cache_strategy: ["lightweight"]
prompt_compression_strategy: ["lightweight"] # keep
cache_length_pattern: "tile"  # More compression at lower layers, TODO: use with differnt length patterns
global_tokens: 4 # keep
recent_window: 10 # keep
model_type: "linear" # TODO: use differnt model types
trained_weights: "none" # "./lightweight_weights/Qwen2-0.5B-Instruct/20250124_105117_linear.pth"
# max_cache_length: [1024]